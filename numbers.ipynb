{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "\n",
    "train_dataset = dset.MNIST(root = 'data/', train = True, download = True)\n",
    "test_dataset = dset.MNIST(root = 'data/', train = False, download = True)\n",
    "\n",
    "train_images = train_dataset.data\n",
    "train_labels = train_dataset.targets\n",
    "\n",
    "test_images = test_dataset.data\n",
    "test_labels = test_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "#apply transformations to dataset\n",
    "train_dataset = dset.MNIST(root = 'data/', train = True, download = True, transform = transform)\n",
    "test_dataset = dset.MNIST(root = 'data/', train = False, download = True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, figsize \u001b[39m=\u001b[39m (\u001b[39m10\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i, ax \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(axes):\n\u001b[0;32m----> 6\u001b[0m     ax\u001b[39m.\u001b[39mimshow(train_dataset\u001b[39m.\u001b[39mdata[i], cmap \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     ax\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#verify data\n",
    "fig, axes = plt.subplots(1, 10, figsize = (10, 1))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(train_dataset.data[i], cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.0555\n",
      "Epoch: 2, Loss: 0.0166\n",
      "Epoch: 3, Loss: 0.1357\n",
      "Epoch: 4, Loss: 0.0194\n",
      "Epoch: 5, Loss: 0.0292\n",
      "Epoch: 6, Loss: 0.0007\n",
      "Epoch: 7, Loss: 0.1114\n",
      "Epoch: 8, Loss: 0.0052\n",
      "Epoch: 9, Loss: 0.0000\n",
      "Epoch: 10, Loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "class numbers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(numbers, self).__init__()\n",
    "        #define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 32, 10)\n",
    "\n",
    "    #define forward pass\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #flatten\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "model = numbers()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "#train model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')  \n",
    "\n",
    "#save model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numbers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m#load model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m numbers()\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[39m#dictionary to label all the classes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numbers' is not defined"
     ]
    }
   ],
   "source": [
    "#create gui\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "#load model\n",
    "model = numbers()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "#dictionary to label all the classes\n",
    "classes = {\n",
    "    0: 'Zero',\n",
    "    1: 'One',\n",
    "    2: 'Two',\n",
    "    3: 'Three',\n",
    "    4: 'Four',\n",
    "    5: 'Five',\n",
    "    6: 'Six',\n",
    "    7: 'Seven',\n",
    "    8: 'Eight',\n",
    "    9: 'Nine'\n",
    "}\n",
    "\n",
    "#initialise GUI\n",
    "window = tk.Tk()\n",
    "window.title('Number Classifier')\n",
    "window.geometry('600x600')\n",
    "\n",
    "#initialise drawing area\n",
    "canvas_width = 600\n",
    "canvas_height = 400\n",
    "canvas_colour = 'black'\n",
    "\n",
    "#initialise canvas\n",
    "canvas = tk.Canvas(window, width = canvas_width, height = canvas_height, bg = canvas_colour)\n",
    "canvas.pack()\n",
    "\n",
    "#initialise PIL image\n",
    "img = PIL.Image.new('RGB', (600, 400), canvas_colour)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "#function to clear canvas\n",
    "def clear_canvas():\n",
    "    canvas.delete('all')\n",
    "    draw.rectangle((0, 0, 600, 400), fill = canvas_colour)\n",
    "\n",
    "\n",
    "#function to classify image\n",
    "def classify_image():\n",
    "    #convert image to MNIST format\n",
    "    img_resized = img.resize((28, 28)).convert('L')\n",
    "    img_np = np.array(img_resized)\n",
    "    img_normalized = img_np / 255.0\n",
    "    img_tensor = torch.from_numpy(img_normalized).unsqueeze(0).unsqueeze(0).float()\n",
    "    \n",
    "    #get prediction\n",
    "    outputs = model(img_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    #display prediction\n",
    "    label = tk.Label(window, text=f'Prediction: {classes[predicted.item()]}', font=('Arial', 32))\n",
    "    label.place(x=100, y=450)\n",
    "\n",
    "#function to draw on canvas\n",
    "def draw_on_canvas(event):\n",
    "    x = event.x\n",
    "    y = event.y\n",
    "    r = 8\n",
    "    canvas.create_oval(x - r, y - r, x + r, y + r, fill = 'white')\n",
    "    draw.rectangle((x - r, y - r, x + r, y + r), fill = 'white')\n",
    "\n",
    "#bind mouse drag event to canvas\n",
    "canvas.bind('<B1-Motion>', draw_on_canvas)\n",
    "\n",
    "#add buttons\n",
    "button_clear = tk.Button(window, text = 'Clear', font = ('Arial', 32), command = clear_canvas)\n",
    "button_clear.place(x = 100, y = 500)\n",
    "\n",
    "button_classify = tk.Button(window, text = 'Classify', font = ('Arial', 32), command = classify_image)\n",
    "button_classify.place(x = 300, y = 500)\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "# \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
